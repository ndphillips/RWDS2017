---
title: "FFTrees"
subtitle: "âš”<br/>with xaringan"
author: "Yihui Xie"
date: "2016/12/12"
output:
  xaringan::moon_reader:
    css: ["default", "xaringan.css"]
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      ratio: '16:9'
    seal: false
---
```{r setup, include=FALSE, fig.align = 'center'}
knitr::opts_chunk$set(echo = FALSE, fig.align = 'center')
library(FFTrees)


#  Step 2: Create the FFTrees object
heart_FFT <- FFTrees(formula = diagnosis ~., # Criterion
                     data = heart.train,     # Training data
                     data.test = heart.test, # Testing data
                     main = "Heart Disease", # Optional Labels
                     decision.labels = c("Healthy", "Diseased")) 



htmltools::tagList(rmarkdown::html_dependency_font_awesome())

```

class: title-slide-custom

.pull-left65[

<br><br><br>

## Creating transparent, powerful decision aids with FFTrees

<br>

<font size = 6> Dr. Nathaniel D. Phillips</font>
<br><br><br3>
<font size = 5><i class="fa fa-globe"></i><a href = "http://ndphillips.github.io">   http://ndphillips.github.io</a></font>
<br><br3>
<font size = 5><i class="fa fa-envelope-o"></i>   Nathaniel.D.Phillips.is@gmail.com</font>
<br><br3>

<font size = 5><i class="fa fa-tv"></i>   Slides: <a href='http://ndphillips.github.io/RWDS2017'>http://ndphillips.github.io/RWDS2017</a></font>


<br><br>


<font size = 5>Roche, Real World Data Science (RWDS), 13 November, 2017</font>


<br>
]

.pull-right35[

<br><br><br><br>
```{r, out.width = "100%"}
knitr::include_graphics("images/heartfft.png")
```

]

---

<br><br><br><br><br>

# How can one make good decisions based on limited, complex, noisy information?

---

```{r}
knitr::include_graphics(c("images/three_ex_1.png"))
```

---
count: false

```{r}
knitr::include_graphics(c("images/three_ex_2.png"))
```

---
count: false

```{r}
knitr::include_graphics(c("images/three_ex_3.png"))
```

---
count: false

```{r}
knitr::include_graphics(c("images/three_ex_4.png"))
```

---

```{r, out.width = "100%"}
knitr::include_graphics(c("images/er_busy_1.png"))
```

---
count: false

```{r, out.width = "100%"}
knitr::include_graphics(c("images/er_busy_2.png"))
```

---

```{r, out.width = "100%"}
knitr::include_graphics(c("images/er_decision_1.png"))
```

---
count: false

```{r, out.width = "100%"}
knitr::include_graphics(c("images/er_decision_2.png"))
```

---
count: false

```{r, out.width = "100%"}
knitr::include_graphics(c("images/er_decision_3.png"))
```

---
count: false

```{r, out.width = "100%"}
knitr::include_graphics(c("images/er_decision_4.png"))
```

---
count: false

```{r, out.width = "100%"}
knitr::include_graphics(c("images/er_decision_5.png"))
```

---
count: false

```{r, out.width = "100%"}
knitr::include_graphics(c("images/er_decision_6.png"))
```

---
count: false

```{r, out.width = "100%"}
knitr::include_graphics(c("images/er_decision_7.png"))
```

---
count: false

```{r, out.width = "100%"}
knitr::include_graphics(c("images/er_decision_8.png"))
```


---



.pull-left45[

<br>
<br>
## Why are doctor's decisions so poor?
<br>


<br3>

<font size = 5>- Completely exhausted, overwhelmed</font>

<br3>

<font size = 5>- Idiosyncratic, inconsistent decision rules.</font>

<br3>

<font size = 5>- Defensive decision making</font>

<br3>

<font size = 5>- Extreme overconfidence</font>
]

.pull-right45[

<br>
<br>

```{r, out.width = "90%", fig.cap="<font size = 3>Source: Christensen-Szalanski and James Bushyhead (1981)</font>"}
knitr::include_graphics(c("images/overconfidence_curve.gif"))
```

]


---

.pull-left5[

<br><br><br><br>
##Solution

<font size = 5>A <font color = "blue">Fast-and-Frugal decision tree (FFT)</font> developed by Green & Mehr (1997)<font>
<br>

## Result
<font size = 5>Far fewer false-alarms and huge cost savings<font>
<br4>

<font size = 5>Unlike complex rules (e.g.; regression), was readily accepted by physicians<font>
<br4>

]


.pull-right5[


```{r, out.width = "75%"}
knitr::include_graphics(c("images/greenmehr_fft.png"))
```

<font size = 3>Source: Green & Mehr. (1997). What alters physician's decisions to admit to the coronary care unit?</font>

]


---

.pull-left5[

<br><br><br>
## What is an FFT?
<br2>
<font size=5>A <font color = "blue">Fast-and-Frugal Tree</font> (FFT) is a highly restricted decision tree.</font>
<br4>
<font size=5>Each node in the tree must have exactly 2 branches, where 1 branch is an exit branch leading to a decision leaf.</font>
<br4>
<font size=5>The final node must have 2 exit branches.</font>
<br><br><br><br><br><br>
<font size = 3>Martignon et al. (2003). Naive and yet enlightened: From natural frequencies to fast and frugal decision trees</font>

]


.pull-right5[


```{r, out.width = "75%"}
knitr::include_graphics(c("images/blank_fft_B.png"))
```

]


---

.pull-left5[

<br><br><br>
## What is an FFT?
<br2>
<font size=5>A <font color = "blue">Fast-and-Frugal Tree</font> (FFT) is a highly restricted decision tree.</font>
<br4>
<font size=5>Each node in the tree must have exactly 2 branches, where 1 branch is an exit branch leading to a decision leaf.</font>
<br4>
<font size=5>The final node must have 2 exit branches.</font>
<br><br><br><br><br><br>
<font size = 3>*Martignon et al. (2003). Naive and yet enlightened: From natural frequencies to fast and frugal decision trees*</font>

]


.pull-right5[


```{r, out.width = "75%"}
knitr::include_graphics(c("images/fft_cartoon.png"))
```

]

---

.pull-left35[
<br><br><br>
## Benefits of FFTs
<br2>
<font size = 5>1. Transparent</font>
<br4>
<font size = 5>2. Focus (and ignore)</font>
<br4>

<font size = 5>3. Fast and efficient</font>
<br4>

<font size = 5>4. Difficult to overfit</font>
<br4>

<font size = 5>5. Easy to learn, communicate, and modify</font>
<br4>


]


.pull-right6[
<br><br>

```{r, out.width = "100%"}
knitr::include_graphics(c("images/algorithm_comparison.png"))
```

]


---

.pull-left5[

```{r, out.width = "100%"}
knitr::include_graphics(c("images/fft_examples_images.png"))
```


]

.pull-right5[

```{r, out.width = "75%"}
knitr::include_graphics(c("images/blank_fft_B.png"))
```

]


---

.pull-left5[

```{r, out.width = "100%"}
knitr::include_graphics(c("images/fft_examples_images_depression_focus.png"))
```


]

.pull-right5[

### Depression FFT

```{r, out.width = "75%"}
knitr::include_graphics(c("images/depression_fft.png"))
```

<font size = 3>Jenny et al. (2013). Simple rules for detecting depression.</font>


]



---

.pull-left5[

```{r, out.width = "100%"}
knitr::include_graphics(c("images/fft_examples_images_military_focus.png"))
```


]

.pull-right5[

### Miltary Checkpoint FFT
<br>
<br>
```{r, out.width = "75%"}
knitr::include_graphics(c("images/terrorism_fft.png"))
```

<font size = 3>Keller & Katsikopoulos. (2016). On the role of psychological heuristics in operational research.</font>


]




---


.pull-left5[
<br><br>
### Problem
<br3>
<font size = 5>No off-the-shelf method to create fast-and-frugal trees</font>

### Goal
<br3>
<font size = 5>Create a <font color = "blue">simple tool</font> that allows anyone to create FFTs with minimal programming</font>
<br4>
<font size = 5>Visualise tree decisions using <font color = "blue">icon arrays</font></font>
<br4>
<font size = 5>Emphasize <font color = "blue">training versus prediction</font></font>
<br4>
<font size = 5><font color = "blue">Easily compare</font> FFTs to other algorithms.</font>

## FFTrees

]

.pull-right5[

```{r, out.width = "80%"}
knitr::include_graphics(c("images/rlogo_and_shinyfftrees.png"))
```

]

---
## Ex) Heart Disease

<br3>

<font size = 5><b>Data</b> 150 Training cases, 153 test cases</font>

<br>

| age| sex|cp | trestbps| chol| fbs|restecg     | thalach| exang| oldpeak|slope | ca|thal   | diagnosis|
|---:|---:|:--|--------:|----:|---:|:-----------|-------:|-----:|-------:|:-----|--:|:------|---------:|
|  63|   1|ta |      145|  233|   1|hypertrophy |     150|     0|     2.3|down  |  0|fd     |         0|
|  67|   1|a  |      160|  286|   0|hypertrophy |     108|     1|     1.5|flat  |  3|normal |         1|
|  67|   1|a  |      120|  229|   0|hypertrophy |     129|     1|     2.6|flat  |  2|rd     |         1|
|  37|   1|np |      130|  250|   0|normal      |     187|     0|     3.5|down  |  0|normal |         0|
|  41|   0|aa |      130|  204|   0|hypertrophy |     172|     0|     1.4|up    |  0|normal |         0|
|  56|   1|aa |      120|  236|   0|normal      |     178|     0|     0.8|up    |  0|normal |         0|

<br>

<font size = 5><b>Goal</b> Predict binary criterion (diagnosis) from a set of 13 numeric and factor features</font>
<br4>


<font size = 3>Source: UCI Machine Learning Database</font>



---
## 4 Steps to using FFTrees in R

.pull-left15[
<br3><br3>
<br>
<br>
<font size = 5>0.Install</font>
<br><br>

<font size = 5>1. Load</font>
<br>

<font size = 5>2. Create</font>
<br>
<br><br>
<br><br><br4>
<font size = 5>3. Print</font>
<br><br>

<font size = 5>4. Plot</font>
<br>

]

.pull-right85[

<br>

```{r, eval = FALSE, echo = TRUE}
# Step 0: Install FFTrees from CRAN
install.packages("FFTrees")

# Step 1: Load FFTrees
library(FFTrees)

#  Step 2: Create the FFTrees object
heart_FFT <- FFTrees(formula = diagnosis ~., # Criterion
                     data = heart.train,     # Training data
                     data.test = heart.test, # Testing data
                     main = "Heart Disease", # Optional Labels
                     decision.labels = c("Healthy", "Diseased")) 

# Step 3: Print the object
heart_FFT

# Step 4: Plot the tree and accuracy statistics
plot(heart_FFT)
```

]

---
## plot(heart_FFT, stats = FALSE)

---
count: false


## plot(heart_FFT, stats = FALSE)

.pull-left5[

```{r, out.width = "70%"}
knitr::include_graphics("images/heart_fft_nostats_2.png")
```

]

.pull-right5[
<br><br><br>
###thal
<br2>

<font size=5>Imaging test that measures blood flow to the heart</font>

### cp
<br2>

<font size=5>Type of chest pain</font>

### ca
<br2>

<font size=5>Number of major vessels colored by fluoroscopy</font>


]
---

## plot(heart_FFT)

---
count: false

## plot(heart_FFT)

.pull-left7[

```{r, out.width = "80%"}
knitr::include_graphics("images/heart_fft_train.png")
```

]

.pull-right3[

<br>

<font size = 5>Dataset description</font>

<br><br>

<font size = 5>Tree and decisions displayed as <b>icon arrays</b>*</font>

<br><br><br>

<font size = 5>Aggregate classification statistics</font>


<br>

<font size = 3>* Galesic, et al. (2009). Using icon arrays to communicate medical risks</font>

]

---
count: false

## plot(heart_FFT)

.pull-left7[

```{r, out.width = "100%"}
knitr::include_graphics("images/heart_train_roc.png")
```

]

.pull-right3[

<br>

<font size = 5>Algorithm comparison in ROC space</font>

<br><br>

<font size = 5>Multiple FFTs with different error trade-offs.</font>

<br><br><br>

]

---

## plot(heart_FFT, data = "test")


.pull-left7[


```{r, out.width = "80%"}
knitr::include_graphics("images/heart_fft_test.png")
```

]

.pull-right3[

<br>

<font size = 5>Easily apply tree to <b>new, test data</b></font>

<br><br>

<font size = 5>Look for changes in when decisions are made, and when <b>errors</b> occur</font>

<br><br><br>

<font size = 5>Compare prediction accuracy to other algorithms</font>


]


---


<h2> &emsp; &emsp; &emsp;    &emsp;Training &emsp; &emsp;  &emsp; &emsp; &emsp;  Testing</h2>

<br><br>
```{r, out.width = "100%"}
knitr::include_graphics("images/train_v_test_roc.png")
```


---

## plot(heart_FFT, data = "test", tree = 7)

.pull-left7[

```{r, out.width = "80%"}
knitr::include_graphics("images/heart_fft_test_tree7.png")
```

]

.pull-right3[

<br><br>

<font size = 5>Explore trees with different <b>exit structures</b> and <b>error trade-offs</b></font>

<br><br>

<font size = 5>Tree #7 has a very low false-alarm rate but a huge number of misses></font>

<br><br>

]

---
## plot(heart_FFT, data = "test", tree = 6)

.pull-left7[

```{r, out.width = "80%"}
knitr::include_graphics("images/heart_fft_test_tree6.png")
```

]

.pull-right3[

<br><br>

<font size = 5>Explore trees with different <b>exit structures</b> and <b>error trade-offs</b></font>

<br><br>

<font size = 5>Tree #6 has very few misses but a huge number of false-alarms></font>

<br><br>
]

---

.pull-left45[

<br><br>
## "Fan" Algorithm

<br>
<font size = 5>1. For each feature, calculate a threshold that maximizes <font color = 'red'>accuracy</font></font>

]

.pull-right45[
<br><br><br>
<font size = 5>What is the best split for feature X?</font>

```{r, out.width = "100%"}
knitr::include_graphics("images/threshold.png")
```


]




---


.pull-left45[
<br><br>
## "Fan" Algorithm
<br>
<font size = 5>1. For each feature, calculate a threshold that maximizes <font color = 'red'>accuracy</font></font>

<br4>

<font size = 5>2. Rank order features by <font color = 'red'>accuracy</font> and select top <font color = 'red'>M</font> features.</font>

]


.pull-right45[
<br><br><br>
<font size = 5>What are the top M features?</font>
<br>
```{r, out.width = "100%"}
knitr::include_graphics("images/selectcues.png")
```


]



---

.pull-left45[
<br><br>
## "Fan" Algorithm

<br>
<font size = 5>1. For each feature, calculate a threshold that maximizes <font color = 'red'>accuracy</font></font>

<br4>


<font size = 5>2. Rank order features by <font color = 'red'>accuracy</font> and select top <font color = 'red'>M</font> features.</font>

<br4>


<font size = 5>3. Create $(M - 1)^2$ trees with all possible exit structures.</font>


]


.pull-right45[
<br><br><br>
```{r, out.width = "100%"}
knitr::include_graphics("images/fft_exits_heart_A.png")
```


]


---
count: false


.pull-left45[

<br><br>
## "Fan" Algorithm

<br>
<font size = 5>1. For each feature, calculate a threshold that maximizes <font color = 'red'>accuracy</font></font>

<br4>


<font size = 5>2. Rank order features by <font color = 'red'>accuracy</font> and select top <font color = 'red'>M</font> features.</font>

<br4>


<font size = 5>3. Create $(M - 1)^2$ trees with all possible exit structures.</font>

]


.pull-right45[
<br><br><br>
```{r, out.width = "100%"}
knitr::include_graphics("images/fft_exits_heart_B.png")
```


]



---
count: false


.pull-left45[
<br><br>
## "Fan" Algorithm


<br>
<font size = 5>1. For each feature, calculate a threshold that maximizes <font color = 'red'>accuracy</font></font>

<br4>



<font size = 5>2. Rank order features by <font color = 'red'>accuracy</font> and select top <font color = 'red'>M</font> features.</font>
<br4>


<font size = 5>3. Create $(M - 1)^2$ trees with all possible exit structures.</font>
<br4>

<font size = 5>4. Select the tree that maximizes <font color = 'red'>accuracy</font></font>


]


.pull-right45[
<br><br><br>
```{r, out.width = "100%"}
knitr::include_graphics("images/fft_exits_roc_A.png")
```

]


---
count: false


.pull-left45[

<br><br>
## "Fan" Algorithm


<br>
<font size = 5>1. For each feature, calculate a threshold that maximizes <font color = 'red'>accuracy</font></font>

<br4>



<font size = 5>2. Rank order features by <font color = 'red'>accuracy</font> and select top <font color = 'red'>M</font> features.</font>
<br4>


<font size = 5>3. Create $(M - 1)^2$ trees with all possible exit structures.</font>
<br4>

<font size = 5>4. Select the tree that maximizes <font color = 'red'>accuracy</font></font>

]


.pull-right45[
<br><br><br>
```{r, out.width = "100%"}
knitr::include_graphics("images/fft_exits_roc_B.png")
```

]


---
count: false



.pull-left45[

<br><br>
## "Fan" Algorithm

<br>
<font size = 5>1. For each feature, calculate a threshold that maximizes <font color = 'red'>accuracy</font></font>

<br4>



<font size = 5>2. Rank order features by <font color = 'red'>accuracy</font> and select top <font color = 'red'>M</font> features.</font>
<br4>


<font size = 5>3. Create $(M - 1)^2$ trees with all possible exit structures.</font>
<br4>

<font size = 5>4. Select the tree that maximizes <font color = 'red'>accuracy</font></font>

]


.pull-right45[
<br><br><br>
```{r, out.width = "100%"}
knitr::include_graphics("images/fft_exits_roc_C.png")
```

]


---
## ShinyFFTrees: http://www.shinyfftrees.org

<iframe src="https://econpsychbasel.shinyapps.io/shinyfftrees/" width="1100" height="500"></iframe>


---


.pull-left3[
<br><br>
## Bonus Features
<br><br>


]


.pull-right6[

]




---


.pull-left3[
<br><br>
## Bonus Features
<br><br>


<font size = 5>1. Missing data? No problem.</font>

]


.pull-right6[
<br><br><br>
```{r, out.width = "100%"}
knitr::include_graphics("images/fft_missing.png")
```


]


---

.pull-left3[
<br><br>
## Bonus Features

<br><br>


<font size = 5>1. Missing data? No problem.</font>

<br4>

<font size = 5>2. Impliment your own custom tree verbally.</font>


]

.pull-right6[
<br>
```{r, out.width = "90%"}
knitr::include_graphics("images/myfft_ss.png")
```


]




---

.pull-left3[

<br><br>
## Bonus Features

<br><br>

<font size = 5>1. Missing data? No problem.</font>

<br4>

<font size = 5>2. Impliment your own custom tree verbally.</font>

<br4>

<font size = 5>3. Minimise feature costs.</font>

]


.pull-right6[
<br><br>
### Heart Disease feature costs

<br>

|     |age  |sex  |cp   |trestbps |chol |fbs  |restecg    |ca     |thal   |
|:----|:----|:----|:----|:--------|:----|:----|:-----|:------|:------|
|cost |$1 |$1 |$1 |$1     |$7 |$5 |$16  |$101 |$103 |


<font size = 5> Create FFTs that <i>minimize</i> costs</font>
<br4>

```{r, eval = FALSE, echo = TRUE}
# Minimise costs
FFTrees(data = heart.train,
        cost.cues = heart.cost,        # Feature costs
        cost.outcomes = c(0, 1, 1, 0), # Outcome costs
        goal = "cost")
```




]


---

.pull-left3[

<br><br>
## Bonus Features

<br><br>

<font size = 5>1. Missing data? No problem.</font>

<br4>

<font size = 5>2. Impliment your own custom tree verbally.</font>

<br4>

<font size = 5>3. Minimise feature costs.</font>

]


.pull-right6[

### Cost Ignorant FFT

```{r, out.width = "80%"}
knitr::include_graphics("images/cost_ignorant_fft.png")
```

| | Cost Ignorant|Cost Minimising |Change |
|------:|:----:|:-----:|:----:|
|     Cost / Patient|    $138|   <font color = "gray">?</font>   |   <font color = "gray">?</font> |
|     Accuracy|    81%|   <font color = "gray">?</font>  | <font color = "gray">?</font>  |

]

---

.pull-left3[

<br><br>
## Bonus Features

<br><br>

<font size = 5>1. Missing data? No problem.</font>

<br4>

<font size = 5>2. Impliment your own custom tree verbally.</font>

<br4>

<font size = 5>3. Minimise feature costs.</font>

]


.pull-right6[

### Cost Minimising FFT

```{r, out.width = "80%"}
knitr::include_graphics("images/cost_minimising_fft.png")
```

| | Cost Ignorant|Cost Minimising |Change |
|------:|:----:|:-----:|:----:|
|     Cost / Patient|    $138| $2     |<font color="blue">-99%</font>    |
|     Accuracy|    81%|77%     |<font color="red">-5%</font>    |

]

---

.pull-left4[

## Neuromuscular diseases in children


<b>Goal</b><br>
Build a decision tree to aid the diagnosis of neuromuscular disorders in children
<br3>
<b>Data</b><br>
146 children from the Great Ormond Street Hospitcal in London suspected of having either *neurogenic* or *myopathic* diseases.
<br3>
<b>Result</b><br>
FFT makes decisions after 2.1 features on average with ~ 85% accuracy

]

.pull-right6[

```{r, out.width = "90%"}
knitr::include_graphics("images/neuromuscular_fft_test.png")
```

]

---

.pull-left5[

## Psychiatric patient release

<b>Goal</b><br>
Build a decision tree to model the likelihood that psychiatric patients will be released from treatment within 5 years.
<br3>
<b>Data</b><br>
Histories of ~1,100 patients at psychiatric clinic in Reichenau characterised by ~ 40 features (demographic and behavioral)
<br3>
<b>Result</b><br>
FFT (not yet public) makes decisions using ~3 features on average with performance similar to regression.

]

.pull-right45[

<br><br>
```{r}
knitr::include_graphics("images/psychiatric_hospital.jpg")
```

]



---
<br><br><br>

# I know what many of you are thinking...

---
<br><br><br>

# I know what many of you are thinking...

<br><br>

<h3>What if I don't care about speed or efficiency?</h3>
<br>

<h3><font color= "blue">How well can a simple FFT actually predict data relative to a complex algorithm?</font></h3>

---

.pull-left5[

## 10 datasets from UCI ML database

```{r, out.width = "100%"}
knitr::include_graphics("images/ten_datasets.png")
```

<br>

<font size = 5>Procedure: 100 50/50 Cross validation simulations</font>
<br3>
<font size = 5>Criterion: Balanced Accuracy</font>
<br3>

$\Large bacc = mean(sens, spec)$

]

.pull-right5[
<br><br>

| title| cases|features |base rate |
|------:|----:|:-----|:----|
|     arrhythmia|    68|280     |0.29    |
|     audiology|    226|70     |0.10    |
|     breast|    683|10     |0.35    |
|     cmc|    1,473|10    |0.35    |
|     credit|    666|16     |0.45    |
|     dermatology|   358|35     |0.31    |
|     heart|   303     |14    |0.46
|     occupancy|   17,895|6     |0.21    |
|     voting|   435     |17    |0.61 |
|     yeast|   1,484     |19    |0.16 |


]

---

.pull-left4[

## Make a Prediction!
<br>

[https://econpsychbasel.shinyapps.io/rwds_pred/](https://econpsychbasel.shinyapps.io/rwds_pred/)

<br>

<font size = 5>What will the median relative accuracy of FFTrees be to Random Forests?</font>

$\Large RelativeAccuracy = \frac{Accuracy(FFTrees)}{Accuracy(RF)}$

1. In the *worst* performing dataset

2. In the *best* performing dataset

3. On *average*


]

.pull-right5[



<iframe src="https://econpsychbasel.shinyapps.io/rwds_pred/"  width="900" height="600"></iframe>
]

---

```{r, out.width = "70%"}
knitr::include_graphics("images/simulation_speed_1.png")
```

---
count: false

```{r, out.width = "70%"}
knitr::include_graphics("images/simulation_speed_2.png")
```

---
count: false

```{r, out.width = "70%"}
knitr::include_graphics("images/simulation_speed_3.png")
```

---

```{r, out.width = "100%"}
knitr::include_graphics("images/simulation_accuracy_1.png")
```

---
count: false
```{r, out.width = "100%"}
knitr::include_graphics("images/simulation_accuracy_2.png")
```

---
count: false

```{r, out.width = "100%"}
knitr::include_graphics("images/simulation_accuracy_3.png")
```

---
count: false

```{r, out.width = "100%"}
knitr::include_graphics("images/simulation_accuracy_4.png")
```

---
count: false

```{r, out.width = "100%"}
knitr::include_graphics("images/simulation_accuracy_5.png")
```

---
count: false

```{r, out.width = "100%"}
knitr::include_graphics("images/simulation_accuracy_6.png")
```

---

```{r, out.width = "100%"}
knitr::include_graphics("images/simulation_accuracy_tree_1.png")
```

---

```{r, out.width = "100%"}
knitr::include_graphics("images/simulation_accuracy_tree_2.png")
```

---
.pull-left3[
## Make a Prediction!

Time to look at the results...


]

.pull-right7[

<iframe src="https://econpsychbasel.shinyapps.io/rwds_results/" width="1100" height="600"></iframe>

]

---

.pull-left6[

### What I've learned from FFTrees

- Simple models can be surprisingly effective, for both small and large datasets.

- There is no one best model. The best model depends on the data and the needs of the decision maker.

- People are are more likely to use decision tools that they can visualise and understand 


]

.pull-right4[



]

---

.pull-left5[

## Next steps with FFTrees

### High Priority

- Write in C++
- Allow for > 2 classes
- Error monitoring and error diagnosis

### Lower priority

- When do FFTs work well and when not?
- Automate crossvalidation to optimize parameters



]

.pull-right5[



]


---

class: title-slide-custom

.pull-left65[

<br><br><br>

## Creating transparent, powerful decision aids with FFTrees

<br>

<font size = 6> Dr. Nathaniel D. Phillips</font>
<br>
<font size = 5><a href = "http://ndphillips.github.io">http://ndphillips.github.io</a></font>
<br><br>

<font size = 5>Roche, Real World Data Science (RWDS)</font>
<br><br>

<font size = 5>13 November, 2017</font>

<br><br><br><br>
<font size = 5> Slides: <a href='http://ndphillips.github.io/RWDS2017'>http://ndphillips.github.io/RWDS2017</a></font>


<br><br>

]

.pull-right35[

<br><br><br><br>
```{r, out.width = "100%"}
knitr::include_graphics("images/heartfft.png")
```

]


---
# Backup Slides


---
## Overfitting

.pull-left5[

<font size=5>Data = Underlying functional form (signal) + irreducible error (noise).</font>
<br>

$\LARGE Y = f(x) + \epsilon$

<br>
<font size=5>A good model will try to approximate the true signal</font>
<br>

$\LARGE E(Y - \widehat{Y})^2 = [f(X) - \widehat{f}(X)]^2 + Var(\epsilon)$

<br>
<font size=5>However, prediction error is a combination of bias *and* variance</font>
<br>

$\large E(PredError) = Var(\hat{f}(x_{0})) + [Bias(\hat{f}(x_{0}))]^2 + Var(\epsilon)$

<br>
*James et al. (2013). An Introduction to Statistical Learning*

]


.pull-right5[

<br>
<br>
Given heavy irreducible noise, a simple model may outperform a complex one.
<br>

```{r, out.width = "90%"}
knitr::include_graphics("images/overfitting_darts.png")
```

]



